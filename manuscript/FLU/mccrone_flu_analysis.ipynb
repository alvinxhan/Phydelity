{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effects of sampling on Phydelity clustering results using A/H3N2 influenza virus sequence data from McCrone et al. (2018)\n",
    "\n",
    "In a within-host viral diversity study of influneza viruses by [McCrone et al. (2018)](https://elifesciences.org/articles/35962), forty-three high-quality transmission pairs were identified based on stringent criteria:  \n",
    "\n",
    "1. Only individuals in a household with symptom onset within a 7 day window are considered to be epidemiologically linked.  \n",
    "2. Transmission event must not have multiple possible donors with the same day of symptom onset.  \n",
    "3. Donor and recipients were not allowed to have symptom onset on the same day, unless the individuals were both index cases for the household.  \n",
    "4. Genetic distance between influenza populations from each household pair as measured by L1-norm must be below the 5th percentile of the community distribution of randomly assigned pairs. \n",
    "\n",
    "Of the forty-three high-quality transmission pairs, thirty-seven of them were A/H3N2 infections. Among them, thirty-two of them were collected during the 2014/2015 season. This Jupyter notebook extracts the A/H3N2 viral sequences collected by McCrone et al. during that season and analyses how well Phydelity is able to recover the transmission pairs as well as the effect of sampling on Phydelity's results. \n",
    "\n",
    "\n",
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import subprocess \n",
    "import itertools \n",
    "import datetime\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import mutual_info_score as mi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Before running this Jupyter notebook, we need to download the repository https://github.com/lauringlab/Host_level_IAV_evolution as well as source data 7 csv file for Figure 3 from the online version of the [article](https://elifesciences.org/articles/35962) by McCrone et al. (2018). \n",
    "\n",
    "We also need ```mafft``` for sequence alignment, ```RAxML``` to generate ML trees and Phydelity already downloaded and installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path to Host_level_IAV_evolution repository \n",
    "repo_path = \"/Users/alvin/Dropbox/temp_phydelity/Host_level_IAV_evolution\" \n",
    "# full path to source data 7 csv file\n",
    "source_data_7_path = \"/Users/alvin/Dropbox/github_repo/Phydelity/manuscript/FLU/elife-35962-fig3-data7-v3.csv\"\n",
    "\n",
    "# full path where this Jupyter notebook is downloaded \n",
    "root_folder_path = \"/Users/alvin/Dropbox/github_repo/Phydelity/manuscript/FLU\" \n",
    "# path to raxml \n",
    "raxml_path = \"raxmlHPC-PTHREADS-AVX2\"\n",
    "# path to mafft \n",
    "mafft_path = \"mafft\"\n",
    "\n",
    "os.chdir(root_folder_path) # make root_folder_path current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsefasta(fname): # parse fasta file, return as dictionary \n",
    "    return {record.name:record.seq for record in SeqIO.parse(fname, \"fasta\")}\n",
    "\n",
    "# calculate assessment metrics \n",
    "def get_metrics(labels_true, labels_pred):\n",
    "    \n",
    "    # sort and count ground truth labels within clusters\n",
    "    pred_label_to_true_lab_count = {}\n",
    "    for p, pred_label in enumerate(labels_pred):\n",
    "        true_label = labels_true[p]\n",
    "        try:\n",
    "            pred_label_to_true_lab_count[pred_label][true_label] += 1\n",
    "        except:\n",
    "            try:\n",
    "                pred_label_to_true_lab_count[pred_label][true_label] = 1\n",
    "            except:\n",
    "                pred_label_to_true_lab_count[pred_label] = {true_label:1}\n",
    "    \n",
    "    # generate confusion matrix \n",
    "    confusion_matrix = {}\n",
    "    for pred_label in pred_label_to_true_lab_count.keys():\n",
    "        \n",
    "        for true_label in set(labels_true):\n",
    "            try:\n",
    "                count = pred_label_to_true_lab_count[pred_label][true_label]\n",
    "            except:\n",
    "                count = 0\n",
    "            \n",
    "            try:\n",
    "                confusion_matrix[true_label].append(count)\n",
    "            except:\n",
    "                confusion_matrix[true_label] = [count]\n",
    "    \n",
    "    confusion_matrix = pd.DataFrame(confusion_matrix)\n",
    "    \n",
    "    # calculate purity using summation of max of each column (class) for each row (cluster) \n",
    "    purity = sum(confusion_matrix.max(axis=1))/len(labels_pred)\n",
    "    \n",
    "    # modified gini \n",
    "    # first, we determine which cluster is the \"correct\" cluster to class \n",
    "    maxc_to_t = {} # nested dictionary of cluster c that subtends the max proportion of class t(s) \n",
    "    for t in confusion_matrix:\n",
    "        # total number of items of class t \n",
    "        total_t = sum(confusion_matrix[t])\n",
    "        \n",
    "        # get dictionary of cluster index c and the proportion of class t it subtends \n",
    "        c_to_tprop = {c:c_count/total_t for c, c_count in enumerate(confusion_matrix[t]) if c_count > 0}\n",
    "        \n",
    "        # get the maximum proportion of class t subtended among all clusters \n",
    "        max_tprop = max(c_to_tprop.values())\n",
    "        \n",
    "        for c, tprop in c_to_tprop.items(): \n",
    "            # if cluster c subtends the max. proportion of class t \n",
    "            if tprop == max_tprop: \n",
    "                try: \n",
    "                    maxc_to_t[c][t] = tprop\n",
    "                except:\n",
    "                    maxc_to_t[c] = {t:tprop}\n",
    "    \n",
    "    # now, we have to make sure that for each class t subtended by cluster c, it is also the largest by \n",
    "    # proportion within the cluster \n",
    "    t_to_maxc = {}\n",
    "    for c, t_to_tprop in maxc_to_t.items():\n",
    "        if len(t_to_tprop) == 1: # cluster only subtends \n",
    "            t = t_to_tprop.keys()[0]\n",
    "            try:\n",
    "                t_to_maxc[t][c] = tprop\n",
    "            except: \n",
    "                t_to_maxc[t] = {c:tprop}\n",
    "        else:\n",
    "            total_counts_in_cluster = sum(confusion_matrix.iloc[c])\n",
    "            t_to_cprop = {t:list(confusion_matrix[t])[c]/total_counts_in_cluster for t in t_to_tprop.keys()}\n",
    "            max_cprop = max(t_to_cprop.values())\n",
    "            \n",
    "            for t, cprop in t_to_cprop.items():\n",
    "                if cprop == max_cprop:\n",
    "                    try:\n",
    "                        t_to_maxc[t][c] = tprop\n",
    "                    except: \n",
    "                        t_to_maxc[t] = {c:tprop}\n",
    "    \n",
    "    # if class t is equally divided across all clusters, then none of the cluster is a \"correct\" cluster to t \n",
    "    for t, c_to_tprop in t_to_maxc.items():\n",
    "        if len(c_to_tprop) == len(set(labels_pred)) and len(set(c_to_tprop.values())) == 1:\n",
    "            t_to_maxc[t] = {}\n",
    "    \n",
    "    # calculate modified gini\n",
    "    gini_index = 0 \n",
    "    for t in list(set(labels_true)):\n",
    "        c_counts = list(confusion_matrix[t])\n",
    "        # get proportion of class t among all tips clustered \n",
    "        p_t = sum(c_counts)/len(labels_true)\n",
    "        \n",
    "        try: \n",
    "            # for class t with a \"correct\" cluster identified \n",
    "            maxc_list = t_to_maxc[t].keys()\n",
    "        except:\n",
    "            # for class t without a \"correct\" cluster \n",
    "            gini_index += p_t\n",
    "            continue \n",
    "        \n",
    "        # get proportion of correctly classifed class t \n",
    "        p_correct = sum([(c_counts[c]/len(labels_true))/p_t for c in maxc_list])\n",
    "        \n",
    "        gini_index += p_t*(1-p_correct)\n",
    "    \n",
    "    ari_score = ari(labels_true, labels_pred)\n",
    "    mi = mi_score(labels_true, labels_pred)\n",
    "    true_H = entropy([labels_true.count(lab) / len(labels_true) for lab in list(set(labels_true))])\n",
    "    pred_H = entropy([labels_pred.count(lab) / len(labels_pred) for lab in list(set(labels_pred))])\n",
    "    nmi = 2*mi/(pred_H + true_H)\n",
    "    \n",
    "    return purity, gini_index, ari_score, nmi \n",
    "    \n",
    "# calculate information entropy\n",
    "def entropy(probability_distribution):\n",
    "    return -sum([p * np.log(p) for p in probability_distribution])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract transmission pairs and sequence data generated by McCrone et al. (2018)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 high-quality transmission pairs collected in 2014/2015 season.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nb</th>\n",
       "      <th>CI</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>donor_sample</th>\n",
       "      <th>recipient_sample</th>\n",
       "      <th>estimated_transmission_date</th>\n",
       "      <th>Donor_age</th>\n",
       "      <th>Recipient_age</th>\n",
       "      <th>minority_isnv</th>\n",
       "      <th>transmitted_minority_isnv</th>\n",
       "      <th>ENROLLID1</th>\n",
       "      <th>ENROLLID2</th>\n",
       "      <th>SPECID1</th>\n",
       "      <th>SPECID2</th>\n",
       "      <th>Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1-29</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>37.024716</td>\n",
       "      <td>3.616775</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50001</td>\n",
       "      <td>50004</td>\n",
       "      <td>HS1563</td>\n",
       "      <td>HS1564</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1-40</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>37.024716</td>\n",
       "      <td>6.149339</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50001</td>\n",
       "      <td>50003</td>\n",
       "      <td>HS1563</td>\n",
       "      <td>MH8690</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1-39</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>6.149339</td>\n",
       "      <td>3.616775</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50003</td>\n",
       "      <td>50004</td>\n",
       "      <td>MH8690</td>\n",
       "      <td>HS1564</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1-39</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>6.149339</td>\n",
       "      <td>37.024716</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50003</td>\n",
       "      <td>50001</td>\n",
       "      <td>MH8690</td>\n",
       "      <td>HS1563</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1-200</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>3.616775</td>\n",
       "      <td>37.024716</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50004</td>\n",
       "      <td>50001</td>\n",
       "      <td>HS1564</td>\n",
       "      <td>HS1563</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nb     CI Subtype donor_sample recipient_sample  \\\n",
       "9   1   1-29  A/H3N2   2014-12-25       2014-12-25   \n",
       "10  1   1-40  A/H3N2   2014-12-25       2014-12-31   \n",
       "11  1   1-39  A/H3N2   2014-12-31       2014-12-25   \n",
       "12  1   1-39  A/H3N2   2014-12-31       2014-12-25   \n",
       "14  1  1-200  A/H3N2   2014-12-25       2014-12-25   \n",
       "\n",
       "   estimated_transmission_date  Donor_age  Recipient_age  minority_isnv  \\\n",
       "9                   2014-12-24  37.024716       3.616775              2   \n",
       "10                  2014-12-24  37.024716       6.149339              2   \n",
       "11                  2014-12-24   6.149339       3.616775              2   \n",
       "12                  2014-12-24   6.149339      37.024716              2   \n",
       "14                  2014-12-24   3.616775      37.024716              1   \n",
       "\n",
       "    transmitted_minority_isnv ENROLLID1 ENROLLID2 SPECID1 SPECID2  Used  \n",
       "9                           0     50001     50004  HS1563  HS1564  True  \n",
       "10                          0     50001     50003  HS1563  MH8690  True  \n",
       "11                          0     50003     50004  MH8690  HS1564  True  \n",
       "12                          0     50003     50001  MH8690  HS1563  True  \n",
       "14                          0     50004     50001  HS1564  HS1563  True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read pairs data \n",
    "pairs_df = pd.read_csv(source_data_7_path, index_col=0)\n",
    "pairs_df[\"estimated_transmission_date\"] = pd.to_datetime(pairs_df[\"estimated_transmission_date\"])\n",
    "# only consider high-quality transmission pairs of A/H3N2 subtype sampled in 2014/2015 season\n",
    "pairs_df = pairs_df[(pairs_df[\"Used\"]==True)&(pairs_df[\"Subtype\"]==\"A/H3N2\")&(pairs_df[\"estimated_transmission_date\"]>=pd.Timestamp(2014, 1, 1))] # H3N2 only \n",
    "print \"{} high-quality transmission pairs collected in 2014/2015 season.\".format(len(pairs_df))\n",
    "pairs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the transmission pairs have overlapping donors and recipents. As such, we resolve such pairs into transmission clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transmission clusters: 22\n",
      "{2: 16, 3: 6}\n"
     ]
    }
   ],
   "source": [
    "all_transmission_clusters = []\n",
    "\n",
    "for r, row in pairs_df.iterrows():\n",
    "    specid1 = row[\"SPECID1\"]\n",
    "    specid2 = row[\"SPECID2\"]\n",
    "\n",
    "    paired112 = list(pairs_df[pairs_df[\"SPECID1\"]==specid1][\"SPECID2\"])    \n",
    "    paired221 = list(pairs_df[pairs_df[\"SPECID2\"]==specid2][\"SPECID1\"])\n",
    "    \n",
    "    paired122 = list(pairs_df[pairs_df[\"SPECID1\"]==specid2][\"SPECID2\"])\n",
    "    paired211 = list(pairs_df[pairs_df[\"SPECID2\"]==specid1][\"SPECID1\"])\n",
    "    \n",
    "    all_specid_in_cluster = list(set(paired122)|set(paired112)|set(paired221)|set(paired211))\n",
    "    all_specid_in_cluster = sorted(all_specid_in_cluster, key=lambda _: int(re.search(\"\\d+\", _).group()))\n",
    "    all_transmission_clusters.append(tuple(all_specid_in_cluster))\n",
    "\n",
    "all_transmission_clusters = list(set(all_transmission_clusters))\n",
    "# get list of all sequences identified involved in high-quality transmission pairs \n",
    "all_trans_headers = list(set([k for v in all_transmission_clusters for k in v]))\n",
    "\n",
    "print \"Total number of transmission clusters:\", len(all_transmission_clusters)\n",
    "print {c:len([cl for cl in all_transmission_clusters if len(cl)==c]) for c in set(map(len, all_transmission_clusters))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get meta-information of all A/H3N2 sequence datasets collected in the 2014/2015 season. \n",
    "\n",
    "Meta-data file found in Host_level_IAV_evolution repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSE_ID</th>\n",
       "      <th>ENROLLID</th>\n",
       "      <th>SPECID</th>\n",
       "      <th>onset</th>\n",
       "      <th>collect</th>\n",
       "      <th>vaccination_status</th>\n",
       "      <th>pcr_result</th>\n",
       "      <th>LAURING_ID</th>\n",
       "      <th>DPI</th>\n",
       "      <th>season</th>\n",
       "      <th>log_copy_num</th>\n",
       "      <th>gc_ul</th>\n",
       "      <th>HIGHSD</th>\n",
       "      <th>sequenced</th>\n",
       "      <th>home_collected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1191</td>\n",
       "      <td>300825</td>\n",
       "      <td>M53301</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>1101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10-11</td>\n",
       "      <td>2.816367</td>\n",
       "      <td>46.799308</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1191</td>\n",
       "      <td>300828</td>\n",
       "      <td>M53302</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>1102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-11</td>\n",
       "      <td>6.486882</td>\n",
       "      <td>219156.158420</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1191</td>\n",
       "      <td>300827</td>\n",
       "      <td>M53319</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>1103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10-11</td>\n",
       "      <td>4.608481</td>\n",
       "      <td>2899.701461</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300</td>\n",
       "      <td>301236</td>\n",
       "      <td>M53358</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>0</td>\n",
       "      <td>A/H1N1</td>\n",
       "      <td>1104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-11</td>\n",
       "      <td>2.104354</td>\n",
       "      <td>9.082920</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1362</td>\n",
       "      <td>301602</td>\n",
       "      <td>M53375</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>2011-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>A/H3N2</td>\n",
       "      <td>1105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-11</td>\n",
       "      <td>2.625722</td>\n",
       "      <td>30.171270</td>\n",
       "      <td>Y</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOUSE_ID ENROLLID  SPECID      onset    collect  vaccination_status  \\\n",
       "1      1191   300825  M53301 2011-01-01 2011-01-04                   1   \n",
       "2      1191   300828  M53302 2011-01-03 2011-01-04                   1   \n",
       "3      1191   300827  M53319 2010-12-30 2011-01-05                   1   \n",
       "4      1300   301236  M53358 2011-01-12 2011-01-13                   0   \n",
       "5      1362   301602  M53375 2011-01-13 2011-01-14                   1   \n",
       "\n",
       "  pcr_result LAURING_ID  DPI season  log_copy_num          gc_ul HIGHSD  \\\n",
       "1     A/H3N2       1101  3.0  10-11      2.816367      46.799308      N   \n",
       "2     A/H3N2       1102  1.0  10-11      6.486882  219156.158420      N   \n",
       "3     A/H3N2       1103  6.0  10-11      4.608481    2899.701461      N   \n",
       "4     A/H1N1       1104  1.0  10-11      2.104354       9.082920      N   \n",
       "5     A/H3N2       1105  1.0  10-11      2.625722      30.171270      Y   \n",
       "\n",
       "   sequenced  home_collected  \n",
       "1      False               0  \n",
       "2       True               0  \n",
       "3       True               0  \n",
       "4      False               0  \n",
       "5      False               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"{}/data/reference/all_meta.csv\".format(repo_path), index_col=0)\n",
    "meta_df[\"onset\"] = pd.to_datetime(meta_df[\"onset\"])\n",
    "meta_df[\"collect\"] = pd.to_datetime(meta_df[\"collect\"])\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain whole genome consensus sequence data for A/H3N2 viruses \n",
    "\n",
    "Samples were duplicated in the original analyses. Of which, some of them have differences in frequencies of variant alleles. Here, we analyse which the duplicate sample has the highest frequency of the major alllele and use the consensus sequences derived from that duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HS1402': 'HK_6', 'MH8159': 'HK_8', 'HS1518': 'HK_7', 'HS1519': 'HK_7', 'HS1417': 'HK_6', 'HS1535': 'HK_7', 'HS1375': 'HK_6', 'HS1516': 'HK_7', 'MH7440': 'HK_7', 'HS1345': 'HK_6', 'MH7953': 'HK_8', 'MH8090': 'HK_8', 'MH7564': 'HK_7', 'HS1543': 'HK_7', 'HS1465': 'HK_6', 'MH8924': 'HK_2', 'MH7390': 'HK_7', 'HS1536': 'HK_7', 'HS1341': 'HK_6', 'MH8160': 'HK_8', 'MH8386': 'HK_8', 'HS1409': 'HK_6', 'MH7843': 'HK_8', 'MH8126': 'HK_8', 'MH7885': 'HK_8', 'MH8089': 'HK_8', 'MH7687': 'HK_7', 'MH8309': 'HK_8', 'MH8690': 'HK_2', 'HS1416': 'HK_6'}\n"
     ]
    }
   ],
   "source": [
    "# consensus sequence data from Host_level_IAV_evolution depository \n",
    "# read dataframe of duplicated sequences \n",
    "dup_df = pd.read_csv(\"{}/data/processed/secondary/duplicate_sequences.csv\".format(repo_path), index_col=0)\n",
    "\n",
    "# sort minority and majority for duplicated sequences \n",
    "specid_to_major_lane = {}\n",
    "for specid in set(dup_df[\"SPECID_original\"]):\n",
    "    if specid not in list(pairs_df[\"SPECID1\"]) and specid not in list(pairs_df[\"SPECID2\"]):\n",
    "        continue \n",
    "        \n",
    "    fil_df = dup_df[dup_df[\"SPECID_original\"]==specid]\n",
    "    gene_to_major_lane = {}\n",
    "    for gene in set(fil_df[\"chr\"]):\n",
    "        for pos in set(fil_df[fil_df[\"chr\"]==gene][\"pos\"]):\n",
    "            specid_to_var_to_freq = {}\n",
    "            for var in set(fil_df[(fil_df[\"chr\"]==gene)&(fil_df[\"pos\"]==pos)][\"var\"]):\n",
    "                ffil_df = fil_df[(fil_df[\"chr\"]==gene)&(fil_df[\"pos\"]==pos)&(fil_df[\"var\"]==var)]\n",
    "                \n",
    "                try: \n",
    "                    specid_to_var_to_freq[ffil_df[\"SPECID1\"].iloc[0]][var] = ffil_df[\"freq1\"].iloc[0]\n",
    "                except: \n",
    "                    specid_to_var_to_freq[ffil_df[\"SPECID1\"].iloc[0]] = {var:ffil_df[\"freq1\"].iloc[0]}\n",
    "                \n",
    "                try: \n",
    "                    specid_to_var_to_freq[ffil_df[\"SPECID2\"].iloc[0]][var] = ffil_df[\"freq2\"].iloc[0]\n",
    "                except: \n",
    "                    specid_to_var_to_freq[ffil_df[\"SPECID2\"].iloc[0]] = {var:ffil_df[\"freq2\"].iloc[0]}\n",
    "            \n",
    "            max_var = list([max(specid_to_var_to_freq[_]) for _ in specid_to_var_to_freq.keys()])[0]\n",
    "            for s, lane_specid in enumerate(specid_to_var_to_freq.keys()):\n",
    "                if s == 0: \n",
    "                    max_specid_freq = specid_to_var_to_freq[lane_specid][max_var]\n",
    "                    max_specid = lane_specid\n",
    "                else: \n",
    "                    if specid_to_var_to_freq[lane_specid][max_var] > max_specid_freq:\n",
    "                        max_specid_freq = specid_to_var_to_freq[lane_specid][max_var]\n",
    "                        max_specid = lane_specid\n",
    "            \n",
    "            gmajor_lane = max_specid\n",
    "\n",
    "            try: \n",
    "                gene_to_major_lane[gene][gmajor_lane] += 1\n",
    "            except: \n",
    "                try: \n",
    "                    gene_to_major_lane[gene][gmajor_lane] = 1\n",
    "                except:\n",
    "                    gene_to_major_lane[gene] = {gmajor_lane:1}\n",
    "\n",
    "    major_lane_list = [max(v) for k, v in gene_to_major_lane.items()]\n",
    "    try: \n",
    "        specid_to_major_lane[specid] = re.search(\"HK_\\d+\", max(set(major_lane_list), key=lambda _: major_lane_list.count(_))).group()\n",
    "    except: \n",
    "        continue \n",
    "        \n",
    "print (specid_to_major_lane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then retrieve the consensus whole genome sequence data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 A/H3N2 viruses sequenced in total from 81 households.\n",
      "Sample with earliest onset: HS1250 (2014-11-10)\n",
      "Sample with latest onset: MH9547 (2015-01-27)\n"
     ]
    }
   ],
   "source": [
    "specid_to_index = {}\n",
    "specid_to_onset_date = {}\n",
    "specid_to_collect_date = {}\n",
    "\n",
    "total_count = 0\n",
    "for folder in os.listdir(\"{}/data/processed/\".format(repo_path)):\n",
    "    try: \n",
    "        lane = re.search(\"HK_\\d+\", folder).group()\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "    for fname in os.listdir(\"{}/data/processed/{}/parsed_fa\".format(repo_path, folder)):\n",
    "        try: \n",
    "            specid, index = fname.split(\".\")[0].split(\"_\")\n",
    "        except: \n",
    "            continue \n",
    "        \n",
    "        subtype = meta_df[meta_df[\"SPECID\"]==specid][\"pcr_result\"].iloc[0]\n",
    "        onset_date = meta_df[meta_df[\"SPECID\"]==specid][\"onset\"].iloc[0]\n",
    "        collect_date = meta_df[meta_df[\"SPECID\"]==specid][\"collect\"].iloc[0]        \n",
    "            \n",
    "        # ensure that we are retrieving H3N2 sequences with onset date >= 2014 \n",
    "        if subtype != \"H3N2\" or onset_date < pd.Timestamp(2014, 1, 1):\n",
    "            print (specid, subtype, onset_date)\n",
    "            continue\n",
    "        \n",
    "        specid_to_onset_date[specid] = onset_date\n",
    "        specid_to_collect_date[specid] = collect_date\n",
    "        \n",
    "        try: \n",
    "            specid_to_index[specid].append((index,folder))\n",
    "        except: \n",
    "            specid_to_index[specid] = [(index,folder)]\n",
    "\n",
    "print \"{} A/H3N2 viruses sequenced in total from {} households.\".format(len(specid_to_index), \n",
    "                                                                        len(set(meta_df[meta_df[\"SPECID\"].isin(specid_to_onset_date.keys())][\"HOUSE_ID\"])))\n",
    "print \"Sample with earliest onset:\", min(specid_to_onset_date), \"({})\".format(specid_to_onset_date[min(specid_to_onset_date)].date())\n",
    "print \"Sample with latest onset:\", max(specid_to_onset_date), \"({})\".format(specid_to_onset_date[max(specid_to_onset_date)].date())\n",
    "            \n",
    "for specid, lanes in specid_to_index.items():\n",
    "    if specid in specid_to_major_lane:\n",
    "        major_lane_folder = specid_to_major_lane[specid]\n",
    "        specid_to_index[specid] = [_ for _ in lanes if _[-1] == major_lane_folder]\n",
    "\n",
    "# get sequences \n",
    "if not os.path.isfile(\"./concatenated_seqeunces_2014_H3N2.fasta\"):\n",
    "    segments = ['PB2', 'PB1', 'PA', 'HA', 'NP', 'NR', 'M', 'NS']\n",
    "    with open(\"concatenated_seqeunces_2014_H3N2.fasta\", \"w\") as output: \n",
    "        for specid, lanes in specid_to_index.items():\n",
    "            index, folder = lanes[0]\n",
    "            fname = (\"{}/data/processed/{}/parsed_fa/{}_{}.removed.parsed.fasta\".format(repo_path, folder, specid, index))\n",
    "            fdat = parsefasta(fname)\n",
    "            # concatenate gene segments \n",
    "            concatseq = \"\".join([str(fdat[g]) for g in segments])\n",
    "            output.write(\">{}\\n{}\\n\".format(specid, concatseq))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build phylogenetic tree and run Phydelity \n",
    "\n",
    "We construct the phylogenetic tree for all of the sampled A/H3N2 viruses using RAxML (GTRGAMMA) and apply Phydelity for transmission clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_phydelity_k2_sol0_RAxML_bestTree.txt\n"
     ]
    }
   ],
   "source": [
    "tree_folder_path = \"{}/raxml\".format(root_folder_path) # must be full path\n",
    "phydelity_folder_path = \"{}/phydelity\".format(tree_folder_path) # must be full path\n",
    "\n",
    "# make dir for tree_folder_path \n",
    "if not os.path.isdir(tree_folder_path):\n",
    "    os.mkdir(tree_folder_path)\n",
    "    \n",
    "# mafft to align sequences \n",
    "if not os.path.isfile(\"./mafft_concatenated_seqeunces_2014_H3N2.fasta\"):\n",
    "    subprocess.call(\"{} concatenated_seqeunces_2014_H3N2.fasta > mafft_concatenated_seqeunces_2014_H3N2.fasta\".format(mafft_path))\n",
    "\n",
    "# raxml \n",
    "if not os.path.isfile(\"{}/RAxML_bestTree.mccrone_h3n2_2014\".format(tree_folder_path)):\n",
    "    cmd = [raxml_path, \"-T\", \"4\", \"-m\", \"GTRGAMMA\", \"-p\", \"666\", \"-#\", \"10\",\n",
    "           \"-s\", \"mafft_concatenated_seqeunces_2014_H3N2.fasta\", \n",
    "           \"-n\", \"mccrone_h3n2_2014\", \"-w\", tree_folder_path]\n",
    "    subprocess.call(cmd)\n",
    "\n",
    "# apply phydelity \n",
    "try:\n",
    "    phydelity_clstr_file = [fname for fname in os.listdir(phydelity_folder_path) if re.search(\"^cluster_phydelity_\", fname)][0]\n",
    "except: \n",
    "    os.mkdir(phydelity_folder_path)\n",
    "    os.chdir(phydelity_folder_path)\n",
    "    subprocess.call(\"cp {}/RAxML_bestTree.mccrone_h3n2_2014 ./\".format(tree_folder_path), shell=True)\n",
    "    cmd = [\"phydelity.py\", \"--tree\", \"RAxML_bestTree.mccrone_h3n2_2014\", \n",
    "           \"--outgroup\", min(specid_to_onset_date), \"--collapse_zero_branch_length\"]\n",
    "    subprocess.call(cmd)\n",
    "    os.chdir(root_folder_path)\n",
    "    phydelity_clstr_file = [fname for fname in os.listdir(phydelity_folder_path) if re.search(\"^cluster_phydelity_\", fname)][0]\n",
    "print (phydelity_clstr_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse and calculate clustering metrics \n",
    "\n",
    "We then assess the clustering results for the transmission pairs identified by McCrone et al using the same metrics that was used for the simulation runs. Four metrics are computed: \n",
    "\n",
    "1. Purity = Average proportion of members in an inferred cluster belonging to the same true cluster.  \n",
    "2. Modified gini index = Probability of a randomly selected member is incorrectly clustered.  \n",
    "3. Adjusted rand index (ARI) = Corrected-for-chance accuracy of clustering results based on how well combinatorial pairs of members match between their inferred and true clusters; ranges between 0 and 1; the higher the ARI, the more accurate the clustering results.  \n",
    "4. Nomalised mutual information (NMI) = measures the trade-off between clustering quality and number of clusters; ranges between 0 and 1; the lower the NMI, the more is clustering completely random. \n",
    "\n",
    "Due the stringency of how transmission pairs were identified by McCrone et al., we have also analysed the clustering results using household ID of the sequences as ground truth clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Gini</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.790965</td>\n",
       "      <td>0.963980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALL</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>0.993025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analysis-ID               Basis    Purity      Gini       ARI       NMI\n",
       "0         ALL           HOUSEHOLD  0.893750  0.081250  0.790965  0.963980\n",
       "1         ALL  TRANSMISSION_PAIRS  0.977778  0.022222  0.961926  0.993025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phydelity_result_all = pd.read_csv(\"{}/{}\".format(phydelity_folder_path, phydelity_clstr_file), delimiter=\"\\t\")\n",
    "phydelity_result_all[\"TRUE\"] = None\n",
    "\n",
    "unclustered_list = list(set(specid_to_collect_date.keys())-set(phydelity_result_all[\"TAXA\"]))\n",
    "unclustered_df = {\"TAXA\":unclustered_list, \"CLUSTER\":[None]*len(unclustered_list), \"TRUE\":[None]*len(unclustered_list)}\n",
    "# generate meta-data csv file with unclustered sequences to generate tree figure \n",
    "phydelity_result_meta = pd.concat([phydelity_result_all, pd.DataFrame(unclustered_df)], ignore_index=True)\n",
    "\n",
    "trans_header_to_tc = {}\n",
    "for _tc, true_cluster in enumerate(all_transmission_clusters):\n",
    "    for trans_header in true_cluster: \n",
    "        trans_header_to_tc[trans_header] = _tc\n",
    "        \n",
    "        try: \n",
    "            _index = phydelity_result_meta[phydelity_result_meta[\"TAXA\"]==trans_header].index[0]\n",
    "            phydelity_result_meta.at[_index, \"TRUE\"] = _tc\n",
    "        except: \n",
    "            pass \n",
    "        \n",
    "        try: \n",
    "            _index = phydelity_result_all[phydelity_result_all[\"TAXA\"]==trans_header].index[0]\n",
    "            phydelity_result_all.at[_index, \"TRUE\"] = _tc\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "phydelity_result_all[\"HOUSE_ID\"] = None\n",
    "for r, row in phydelity_result_all.iterrows():\n",
    "    phydelity_result_all.at[r, \"HOUSE_ID\"] = int(meta_df[meta_df[\"SPECID\"]==row[\"TAXA\"]][\"HOUSE_ID\"].iloc[0])\n",
    "\n",
    "# meta dataframe \n",
    "phydelity_result_meta[\"HOUSE_ID\"] = None\n",
    "for r, row in phydelity_result_meta.iterrows():\n",
    "    phydelity_result_meta.at[r, \"HOUSE_ID\"] = int(meta_df[meta_df[\"SPECID\"]==row[\"TAXA\"]][\"HOUSE_ID\"].iloc[0])\n",
    "phydelity_result_meta = phydelity_result_meta[[\"TAXA\", \"CLUSTER\", \"TRUE\", \"HOUSE_ID\"]]\n",
    "#phydelity_result_meta = phydelity_result_meta.set_index(\"TAXA\")\n",
    "phydelity_result_meta = phydelity_result_meta.rename(columns={\"TAXA\":\"leaf\", \"CLUSTER\": \"Phydelity\", \"TRUE\": \"tp\", \"HOUSE_ID\":\"Household\"})\n",
    "phydelity_result_meta.to_csv(\"phydelity_result_meta.csv\", index_label=False)\n",
    "    \n",
    "tabulated_results_all = {\"Analysis-ID\":[], \"Basis\":[], \"Purity\":[], \"Gini\":[], \"ARI\":[], \"NMI\":[]}\n",
    "\n",
    "purity, gini, ari_score, nmi = get_metrics(labels_pred=list(phydelity_result_all[\"CLUSTER\"]),\n",
    "                                           labels_true=list(phydelity_result_all[\"HOUSE_ID\"]))\n",
    "tabulated_results_all[\"Analysis-ID\"].append(\"ALL\")\n",
    "tabulated_results_all[\"Basis\"].append(\"HOUSEHOLD\")\n",
    "tabulated_results_all[\"Purity\"].append(purity)\n",
    "tabulated_results_all[\"Gini\"].append(gini)\n",
    "tabulated_results_all[\"ARI\"].append(ari_score)\n",
    "tabulated_results_all[\"NMI\"].append(nmi)\n",
    "\n",
    "purity, gini, ari_score, nmi = get_metrics(labels_pred=list(phydelity_result_all[~pd.isnull(phydelity_result_all[\"TRUE\"])][\"CLUSTER\"]),\n",
    "                                           labels_true=list(phydelity_result_all[~pd.isnull(phydelity_result_all[\"TRUE\"])][\"TRUE\"]))\n",
    "tabulated_results_all[\"Analysis-ID\"].append(\"ALL\")\n",
    "tabulated_results_all[\"Basis\"].append(\"TRANSMISSION_PAIRS\")\n",
    "tabulated_results_all[\"Purity\"].append(purity)\n",
    "tabulated_results_all[\"Gini\"].append(gini)\n",
    "tabulated_results_all[\"ARI\"].append(ari_score)\n",
    "tabulated_results_all[\"NMI\"].append(nmi)\n",
    "\n",
    "tabulated_results_all = pd.DataFrame(tabulated_results_all)[[\"Analysis-ID\", \"Basis\", \"Purity\", \"Gini\", \"ARI\", \"NMI\"]]\n",
    "tabulated_results_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling the data\n",
    "\n",
    "McCrone et al. collected 206 sequences in total. To analyse the effects to clustering results due to lower sampling rates without bias from small sample effects, we randomly downsample the available dataset to either 52 (25%) or 93 (45%) sequences. \n",
    "\n",
    "For effective analysis, we need to ensure that there are some high-quality transmission pairs within the downsampled pool. As such, we varied the proportion (25%, 45% or 70%) of each downsampled pool of sequences consisting of isolates making up the high-quality transmission pairs. 10 distinct random downsamples were generated for each downsample pool/high-quality transmission sequences set and the averaged clustering results were compared against the case where all sequences collected were analysed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>replicate</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Gini</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52-25</td>\n",
       "      <td>0</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.104510</td>\n",
       "      <td>0.681016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52-25</td>\n",
       "      <td>0</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.506284</td>\n",
       "      <td>0.867313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52-45</td>\n",
       "      <td>0</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.520666</td>\n",
       "      <td>0.912625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52-45</td>\n",
       "      <td>0</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52-70</td>\n",
       "      <td>0</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.846377</td>\n",
       "      <td>0.970116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analysis-ID  replicate               Basis    Purity      Gini       ARI  \\\n",
       "0       52-25          0           HOUSEHOLD  0.378378  0.567568  0.104510   \n",
       "1       52-25          0  TRANSMISSION_PAIRS  0.727273  0.181818  0.506284   \n",
       "2       52-45          0           HOUSEHOLD  0.729730  0.162162  0.520666   \n",
       "3       52-45          0  TRANSMISSION_PAIRS  1.000000  0.000000  1.000000   \n",
       "4       52-70          0           HOUSEHOLD  0.897436  0.051282  0.846377   \n",
       "\n",
       "        NMI  \n",
       "0  0.681016  \n",
       "1  0.867313  \n",
       "2  0.912625  \n",
       "3  1.000000  \n",
       "4  0.970116  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_downsampled_sequences = [52, 93] \n",
    "proportion_of_trans_headers = [25, 45, 70] # percent\n",
    "total_replicates = 10\n",
    "min_true_clusters = 3\n",
    "\n",
    "fdat = parsefasta(\"./mafft_concatenated_seqeunces_2014_H3N2.fasta\")\n",
    "\n",
    "tabulated_results_subset = {\"Analysis-ID\":[], \"replicate\":[], \"Basis\":[], \"Purity\":[], \"Gini\":[], \"ARI\":[], \"NMI\":[]}\n",
    "\n",
    "for rep in range(total_replicates):\n",
    "    seed_used = []\n",
    "    for ds, th in itertools.product(total_number_of_downsampled_sequences, proportion_of_trans_headers):\n",
    "        if ds == 93 and th == 70: # only perform 70% analysis for n_seq =52\n",
    "            continue \n",
    "            \n",
    "        # downsample sequences \n",
    "        if os.path.isfile(\"mafft_subset{}_{}_r{}.fasta\".format(ds, th, rep)):\n",
    "            tfdat = parsefasta(\"mafft_subset{}_{}_r{}.fasta\".format(ds, th, rep))\n",
    "            downsampled_trans_headers = pd.DataFrame({header:trans_header_to_tc[header] for header in list(set(tfdat.keys())&set(all_trans_headers))}.items(), columns=[\"TAXA\", \"TRUE\"]).sort_values(by=\"TRUE\") \n",
    "            number_of_clusters_in_ds = len([k for k, v in {n:list(downsampled_trans_headers[\"TRUE\"]).count(n) for n in set(downsampled_trans_headers[\"TRUE\"])}.items() if v >= 2])\n",
    "            n_seq = len(tfdat)\n",
    "        else: \n",
    "            curr_seed = random.choice(range(10000)) \n",
    "            while curr_seed in seed_used:\n",
    "                curr_seed = random.choice(range(10000)) \n",
    "            seed_used.append(curr_seed)\n",
    "            random.seed(curr_seed)\n",
    "            \n",
    "            downsampled_trans_headers = pd.DataFrame({header:trans_header_to_tc[header] for header in random.sample(all_trans_headers, int(ds*(th/100)))}.items(), columns=[\"TAXA\", \"TRUE\"]).sort_values(by=\"TRUE\")\n",
    "            # make sure we have at least 3 true clusters in downsampled_trans_headers \n",
    "            number_of_clusters_in_ds = len([k for k, v in {n:list(downsampled_trans_headers[\"TRUE\"]).count(n) for n in set(downsampled_trans_headers[\"TRUE\"])}.items() if v >= 2])\n",
    "\n",
    "            while number_of_clusters_in_ds < min_true_clusters:\n",
    "                curr_seed = random.choice(range(10000)) \n",
    "                while curr_seed in seed_used:\n",
    "                    curr_seed = random.choice(range(10000)) \n",
    "                seed_used.append(curr_seed)\n",
    "                random.seed(curr_seed)\n",
    "                downsampled_trans_headers = pd.DataFrame({header:trans_header_to_tc[header] for header in random.sample(all_trans_headers, int(ds*(th/100)))}.items(), columns=[\"TAXA\", \"TRUE\"]).sort_values(by=\"TRUE\")\n",
    "                number_of_clusters_in_ds = len([k for k, v in {n:list(downsampled_trans_headers[\"TRUE\"]).count(n) for n in set(downsampled_trans_headers[\"TRUE\"])}.items() if v >= 2])\n",
    "            #print (ds, th, rep, curr_seed, number_of_clusters_in_ds)\n",
    "\n",
    "            downsampled_headers = random.sample(list(set(specid_to_collect_date.keys())-set(all_trans_headers)), ds-len(downsampled_trans_headers))\n",
    "            downsampled_headers += list(downsampled_trans_headers[\"TAXA\"])\n",
    "            n_seq = len(downsampled_headers)\n",
    "\n",
    "            with open(\"mafft_subset{}_{}_r{}.fasta\".format(ds, th, rep), \"w\") as output: \n",
    "                for header in downsampled_headers: \n",
    "                    output.write(\">{}\\n{}\\n\".format(header, fdat[header]))\n",
    "\n",
    "        tree_folder_path = \"{}/subset{}_{}\".format(root_folder_path, ds, th) # must be full path\n",
    "        rep_folder_path = \"{}/r{}\".format(tree_folder_path, rep)\n",
    "        phydelity_folder_path = \"{}/phydelity\".format(rep_folder_path) # must be full path\n",
    "\n",
    "        # make dir for tree_folder_path \n",
    "        if not os.path.isdir(tree_folder_path):\n",
    "            os.mkdir(tree_folder_path)\n",
    "        \n",
    "        # make dir for rep_folder_path\n",
    "        if not os.path.isdir(rep_folder_path):\n",
    "            os.mkdir(rep_folder_path)\n",
    "\n",
    "        # raxml \n",
    "        if not os.path.isfile(\"{}/RAxML_bestTree.subset{}_{}\".format(rep_folder_path, ds, th)):\n",
    "            # root tree to isolate with earliest onset\n",
    "            outgroup_header = min({header:specid_to_onset_date[header] for header in downsampled_headers})\n",
    "            # run raxml\n",
    "            cmd = [raxml_path, \"-T\", \"4\", \"-m\", \"GTRGAMMA\", \"-p\", \"666\", \"-#\", \"10\",\n",
    "                   \"-s\", \"mafft_subset{}_{}_r{}.fasta\".format(ds, th, rep), \n",
    "                   \"-n\", \"subset{}_{}\".format(ds, th), \"-w\", rep_folder_path]\n",
    "            subprocess.call(cmd)\n",
    "\n",
    "        # apply phydelity \n",
    "        try:\n",
    "            phydelity_clstr_file = [fname for fname in os.listdir(phydelity_folder_path) if re.search(\"^cluster_phydelity_\", fname)][0]\n",
    "        except: \n",
    "            if not os.path.isdir(phydelity_folder_path):\n",
    "                os.mkdir(phydelity_folder_path)\n",
    "            os.chdir(phydelity_folder_path)\n",
    "            subprocess.call(\"cp {}/RAxML_bestTree.subset{}_{} ./\".format(rep_folder_path, ds, th), shell=True)\n",
    "            cmd = [\"phydelity.py\", \"--tree\", \"RAxML_bestTree.subset{}_{}\".format(ds, th), \n",
    "                   \"--outgroup\", outgroup_header, \"--collapse_zero_branch_length\", \"--pdf_tree\"]\n",
    "            subprocess.call(cmd)\n",
    "            os.chdir(root_folder_path)\n",
    "            phydelity_clstr_file = [fname for fname in os.listdir(phydelity_folder_path) if re.search(\"^cluster_phydelity_\", fname)][0]\n",
    "\n",
    "        phydelity_result_subset = pd.read_csv(\"{}/{}\".format(phydelity_folder_path, phydelity_clstr_file), delimiter=\"\\t\")\n",
    "        phydelity_result_subset[\"TRUE\"] = None\n",
    "\n",
    "        for _tc, true_cluster in enumerate(all_transmission_clusters):\n",
    "            for _ in true_cluster: \n",
    "                try: \n",
    "                    _index = phydelity_result_subset[phydelity_result_subset[\"TAXA\"]==_].index[0]\n",
    "                    phydelity_result_subset.at[_index, \"TRUE\"] = _tc\n",
    "                except: \n",
    "                    continue\n",
    "\n",
    "        phydelity_result_subset[\"HOUSE_ID\"] = None\n",
    "        for r, row in phydelity_result_subset.iterrows():\n",
    "            phydelity_result_subset.at[r, \"HOUSE_ID\"] = int(meta_df[meta_df[\"SPECID\"]==row[\"TAXA\"]][\"HOUSE_ID\"].iloc[0])\n",
    "\n",
    "        purity, gini, ari_score, nmi = get_metrics(labels_pred=list(phydelity_result_subset[\"CLUSTER\"]),\n",
    "                                                  labels_true=list(phydelity_result_subset[\"HOUSE_ID\"]))\n",
    "        tabulated_results_subset[\"Analysis-ID\"].append(\"{}-{}\".format(ds, th))\n",
    "        tabulated_results_subset[\"replicate\"].append(rep)\n",
    "        tabulated_results_subset[\"Basis\"].append(\"HOUSEHOLD\")    \n",
    "        tabulated_results_subset[\"Purity\"].append(purity)\n",
    "        tabulated_results_subset[\"Gini\"].append(gini)\n",
    "        tabulated_results_subset[\"ARI\"].append(ari_score)\n",
    "        tabulated_results_subset[\"NMI\"].append(nmi)\n",
    "\n",
    "        purity, gini, ari_score, nmi = get_metrics(labels_pred=list(phydelity_result_subset[~pd.isnull(phydelity_result_subset[\"TRUE\"])][\"CLUSTER\"]), \n",
    "                                                  labels_true=list(phydelity_result_subset[~pd.isnull(phydelity_result_subset[\"TRUE\"])][\"TRUE\"]))\n",
    "        tabulated_results_subset[\"Analysis-ID\"].append(\"{}-{}\".format(ds, th))\n",
    "        tabulated_results_subset[\"replicate\"].append(rep)\n",
    "        tabulated_results_subset[\"Basis\"].append(\"TRANSMISSION_PAIRS\")\n",
    "        tabulated_results_subset[\"Purity\"].append(purity)\n",
    "        tabulated_results_subset[\"Gini\"].append(gini)\n",
    "        tabulated_results_subset[\"ARI\"].append(ari_score)\n",
    "        tabulated_results_subset[\"NMI\"].append(nmi)\n",
    "\n",
    "tabulated_results_subset = pd.DataFrame(tabulated_results_subset)[[\"Analysis-ID\", \"replicate\", \"Basis\", \"Purity\", \"Gini\", \"ARI\", \"NMI\"]]\n",
    "tabulated_results_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI</th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Gini</th>\n",
       "      <th>NMI</th>\n",
       "      <th>Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800741</td>\n",
       "      <td>93-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>0.953457</td>\n",
       "      <td>0.868013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898362</td>\n",
       "      <td>93-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.980917</td>\n",
       "      <td>0.942437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345184</td>\n",
       "      <td>52-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>0.562839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717998</td>\n",
       "      <td>52-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>0.932114</td>\n",
       "      <td>0.870808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.744397</td>\n",
       "      <td>52-70</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.113450</td>\n",
       "      <td>0.928044</td>\n",
       "      <td>0.818475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.761619</td>\n",
       "      <td>52-70</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.069640</td>\n",
       "      <td>0.943068</td>\n",
       "      <td>0.850879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.563890</td>\n",
       "      <td>52-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.898070</td>\n",
       "      <td>0.726313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.737286</td>\n",
       "      <td>52-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.950013</td>\n",
       "      <td>0.870330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.635009</td>\n",
       "      <td>93-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>0.754083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.881796</td>\n",
       "      <td>93-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>0.979408</td>\n",
       "      <td>0.943546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ARI Analysis-ID               Basis      Gini       NMI    Purity\n",
       "0  0.800741       93-45           HOUSEHOLD  0.108466  0.953457  0.868013\n",
       "1  0.898362       93-45  TRANSMISSION_PAIRS  0.029919  0.980917  0.942437\n",
       "2  0.345184       52-25           HOUSEHOLD  0.285097  0.817225  0.562839\n",
       "3  0.717998       52-25  TRANSMISSION_PAIRS  0.061515  0.932114  0.870808\n",
       "4  0.744397       52-70           HOUSEHOLD  0.113450  0.928044  0.818475\n",
       "5  0.761619       52-70  TRANSMISSION_PAIRS  0.069640  0.943068  0.850879\n",
       "6  0.563890       52-45           HOUSEHOLD  0.158058  0.898070  0.726313\n",
       "7  0.737286       52-45  TRANSMISSION_PAIRS  0.040606  0.950013  0.870330\n",
       "8  0.635009       93-25           HOUSEHOLD  0.163730  0.918509  0.754083\n",
       "9  0.881796       93-25  TRANSMISSION_PAIRS  0.026836  0.979408  0.943546"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_tabulated_results_subset = {\"Analysis-ID\":[], \"Basis\":[], \"Purity\":[], \"Gini\":[], \"ARI\":[], \"NMI\":[]}\n",
    "\n",
    "for analysis_id in set(tabulated_results_subset[\"Analysis-ID\"]):\n",
    "    fil_df = tabulated_results_subset[tabulated_results_subset[\"Analysis-ID\"]==analysis_id]\n",
    "    for basis in set(fil_df[\"Basis\"]):\n",
    "        basis_fil_df = fil_df[fil_df[\"Basis\"]==basis]\n",
    "        \n",
    "        averaged_tabulated_results_subset[\"Analysis-ID\"].append(analysis_id)\n",
    "        averaged_tabulated_results_subset[\"Basis\"].append(basis)\n",
    "        averaged_tabulated_results_subset[\"Purity\"].append(np.mean(basis_fil_df[\"Purity\"]))\n",
    "        averaged_tabulated_results_subset[\"Gini\"].append(np.mean(basis_fil_df[\"Gini\"]))\n",
    "        averaged_tabulated_results_subset[\"ARI\"].append(np.mean(basis_fil_df[\"ARI\"]))\n",
    "        averaged_tabulated_results_subset[\"NMI\"].append(np.mean(basis_fil_df[\"NMI\"]))\n",
    "\n",
    "averaged_tabulated_results_subset = pd.DataFrame(averaged_tabulated_results_subset)\n",
    "averaged_tabulated_results_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alvin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Gini</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.562839</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.345184</td>\n",
       "      <td>0.817225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.870808</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>0.717998</td>\n",
       "      <td>0.932114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.726313</td>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.563890</td>\n",
       "      <td>0.898070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.870330</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.737286</td>\n",
       "      <td>0.950013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52-70</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.113450</td>\n",
       "      <td>0.744397</td>\n",
       "      <td>0.928044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52-70</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.850879</td>\n",
       "      <td>0.069640</td>\n",
       "      <td>0.761619</td>\n",
       "      <td>0.943068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.754083</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.635009</td>\n",
       "      <td>0.918509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>93-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.979408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.868013</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>0.800741</td>\n",
       "      <td>0.953457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.898362</td>\n",
       "      <td>0.980917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.790965</td>\n",
       "      <td>0.963980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALL</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>0.993025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Analysis-ID               Basis    Purity      Gini       ARI       NMI\n",
       "4        52-25           HOUSEHOLD  0.562839  0.285097  0.345184  0.817225\n",
       "5        52-25  TRANSMISSION_PAIRS  0.870808  0.061515  0.717998  0.932114\n",
       "8        52-45           HOUSEHOLD  0.726313  0.158058  0.563890  0.898070\n",
       "9        52-45  TRANSMISSION_PAIRS  0.870330  0.040606  0.737286  0.950013\n",
       "6        52-70           HOUSEHOLD  0.818475  0.113450  0.744397  0.928044\n",
       "7        52-70  TRANSMISSION_PAIRS  0.850879  0.069640  0.761619  0.943068\n",
       "10       93-25           HOUSEHOLD  0.754083  0.163730  0.635009  0.918509\n",
       "11       93-25  TRANSMISSION_PAIRS  0.943546  0.026836  0.881796  0.979408\n",
       "2        93-45           HOUSEHOLD  0.868013  0.108466  0.800741  0.953457\n",
       "3        93-45  TRANSMISSION_PAIRS  0.942437  0.029919  0.898362  0.980917\n",
       "0          ALL           HOUSEHOLD  0.893750  0.081250  0.790965  0.963980\n",
       "1          ALL  TRANSMISSION_PAIRS  0.977778  0.022222  0.961926  0.993025"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = pd.concat([tabulated_results_all, averaged_tabulated_results_subset], ignore_index=True).sort_values(by=\"Analysis-ID\")\n",
    "combined_results = combined_results[[\"Analysis-ID\", \"Basis\", \"Purity\", \"Gini\", \"ARI\", \"NMI\"]]\n",
    "combined_results.to_csv(\"combined_results.csv\", index=False)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Gini</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.870808</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>0.717998</td>\n",
       "      <td>0.932114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.870330</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.737286</td>\n",
       "      <td>0.950013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52-70</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.850879</td>\n",
       "      <td>0.069640</td>\n",
       "      <td>0.761619</td>\n",
       "      <td>0.943068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>93-25</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.979408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93-45</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.898362</td>\n",
       "      <td>0.980917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALL</td>\n",
       "      <td>TRANSMISSION_PAIRS</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>0.993025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Analysis-ID               Basis    Purity      Gini       ARI       NMI\n",
       "5        52-25  TRANSMISSION_PAIRS  0.870808  0.061515  0.717998  0.932114\n",
       "9        52-45  TRANSMISSION_PAIRS  0.870330  0.040606  0.737286  0.950013\n",
       "7        52-70  TRANSMISSION_PAIRS  0.850879  0.069640  0.761619  0.943068\n",
       "11       93-25  TRANSMISSION_PAIRS  0.943546  0.026836  0.881796  0.979408\n",
       "3        93-45  TRANSMISSION_PAIRS  0.942437  0.029919  0.898362  0.980917\n",
       "1          ALL  TRANSMISSION_PAIRS  0.977778  0.022222  0.961926  0.993025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results[combined_results[\"Basis\"]==\"TRANSMISSION_PAIRS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis-ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Gini</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.562839</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.345184</td>\n",
       "      <td>0.817225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.726313</td>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.563890</td>\n",
       "      <td>0.898070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52-70</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.113450</td>\n",
       "      <td>0.744397</td>\n",
       "      <td>0.928044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93-25</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.754083</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.635009</td>\n",
       "      <td>0.918509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93-45</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.868013</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>0.800741</td>\n",
       "      <td>0.953457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.790965</td>\n",
       "      <td>0.963980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Analysis-ID      Basis    Purity      Gini       ARI       NMI\n",
       "4        52-25  HOUSEHOLD  0.562839  0.285097  0.345184  0.817225\n",
       "8        52-45  HOUSEHOLD  0.726313  0.158058  0.563890  0.898070\n",
       "6        52-70  HOUSEHOLD  0.818475  0.113450  0.744397  0.928044\n",
       "10       93-25  HOUSEHOLD  0.754083  0.163730  0.635009  0.918509\n",
       "2        93-45  HOUSEHOLD  0.868013  0.108466  0.800741  0.953457\n",
       "0          ALL  HOUSEHOLD  0.893750  0.081250  0.790965  0.963980"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results[combined_results[\"Basis\"]==\"HOUSEHOLD\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
